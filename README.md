# ML_Deploy_GCP_AWS_Lambda_Docker
Deploy Iris flower prediction model on various cloud technologies:

There are 3 main ways to deploy ML models:
1. Fully Managed AI Cloud - AWS Sagemaker, Azure ML, Google AI
2. Serverless cloud - AWS lambda, Google Cloud Function, Azure Function
3. Dockerized microservice based deployment - Dockerized Flask / Django on AWS EC2 instance etc

Here we deploy on the following:

Deploy Scikit-learn, Tensorflow 2.0 Model with Flask Web Framework
Deploy Model on Google cloud function, App engine
Serve model through Google AI Platform
Run Prediction API on Heroku Cloud
Serialize and Deserialize model through Scikit-learn and Tensorflow
Deploying model on Amazon AWS Lambda from linux/windows with serverless
Install Flower prediction model with Docker
Deploy Docker Container on Amazon Container Services (ECS)
